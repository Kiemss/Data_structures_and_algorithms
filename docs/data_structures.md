# 线性表

## 动态数组（实现顺序表）

* 特点：内存连续

1. 优点
   * 下标访问（随机访问）时间复杂度是O(1)
   * 尾删、尾插时间复杂度是O(1)
   * 访问元素前后相邻位置的元素非常方便

2. 缺点
   * 非末尾位置增删元素需要进行大量的数据移动
   * 搜索的时间复杂度
     * 无序数组：线性搜索O(n)
     * 有序数组：二分搜索O($\log{n}$)
   * 数组扩容消耗比较大

3. 适用场景
   * **需要频繁随机访问**的场景
   * **尾部操作频繁**的场景
   * **数据量相对固定**或**可预测**的情况
   * **缓存友好**的高性能计算

## 链表

* 特点：每一个节点都是在堆内存上独立new出来的，节点内存不连续

1. 优点
   * 内存利用率高，不需要大块连续内存
   * 插入和删除节点不需要移动其他节点，时间复杂度O(1)
   * 不需要专门进行扩容操作

2. 缺点
   * 内存占用量大，每一个节点多处存放地址的空间
   * 节点内存不连续，无法进行内存随机访问
   * 链表搜索效率不高，只能从头结点开始逐节点遍历

3. 适用场景
   * **频繁在任意位置插入删除**的场景
   * **内存碎片化**的环境
   * **数据规模动态变化**的情况
   * **实现队列、栈**等数据结构

4. 注意事项
   * 对于使用智能指针管理的链表，常用**原始指针**进行遍历，使用**智能指针**进行节点管理
   * 对于循环链表，用cur_ptr是否等于头节点进行判断；而对于非循环链表，用cur_ptr是否为空进行判断
   * 对于单项链表，由于节点的所有权在上一个节点，因此常用双链表进行节点操作
   * 对于有尾节点的链表，需要注意边界问题。

### 单向链表

* 特点：
  1. 每一个节点除了数据域，还有一个next指针指向下一个节点的地址。但是无法回退到前一个节点
  2. 末尾节点的指针域是nullptr

* 适用场景：
  * **简单的先进先出队列**
  * **只需要单向遍历**的场景
  * **内存极度受限**的环境

### 单向循环链表

* 特点：末尾节点的地址域存储的是首节点的地址

* 适用场景：
  * **轮询调度算法**
  * **环形缓冲区**
  * **约瑟夫环**等问题

### 双向链表

* 特点：
  1. 每一个节点除了数据域，还有next指针指向下一个节点，pre指针指向前一个节点
  2. 头结点的pre是nullptr，末尾节点的next是nullptr

* 适用场景：
  * **需要双向遍历**的场景
  * **LRU缓存淘汰算法**
  * **文本编辑器**的光标移动

### 双向循环链表

* 特点：
  1. 每一个节点除了数据域，还有next指针指向下一个节点，pre指针指向前一个节点
  2. 头节点的pre指向末尾节点，末尾节点的pre指向头节点

* 适用场景：
  * **需要循环双向遍历**的场景
  * **音乐播放列表**
  * **浏览器历史记录**导航

## 栈

* 特点：先进后出，后进先出

### 顺序栈

依赖数组实现

* 适用场景：
  * **固定大小**的栈需求
  * **性能要求高**的场景
  * **内存连续**访问模式

### 链式栈

依赖链表实现

* 适用场景：
  * **动态大小**的栈需求
  * **内存受限**的环境
  * **不需要随机访问**的场景

## 队列

* 特点：先进先出，后进后出

* 适用场景：
  * **任务调度系统**
  * **消息队列**
  * **广度优先搜索**
  * **缓存系统**

# 搜索

## 二分搜索

⭐二分搜索严格要求数据有序！

* 时间复杂度$O(\log_2{n})$
* 空间复杂度
  * 迭代$O(1)$
  * 递归$O(\log_2n)$

* 适用场景：
  * **静态有序数据集**
  * **需要频繁搜索**的场景
  * **数据量较大**的情况

## 排序算法

关注算法的**时间复杂度（平均、最优、最差）**和**空间复杂度**和**稳定性**。

---

## 1. 冒泡排序（Bubble Sort）

- **特点**：相邻元素两两比较，把值大的元素往下交换（沉底），每轮将最大元素放到最终位置。
- **优点**：实现简单，稳定排序。
- **缺点**：数据交换次数太多，时间复杂度高，效率低。
- **时间复杂度**：
  - 平均：O(n²)
  - 最坏：O(n²)
  - 最好：O(n)（已优化情况下，若已有序可提前结束）
- **空间复杂度**：O(1)
- **适用场景**：
  * **教学演示**算法原理
  * **小规模数据**排序（n < 50）
  * **检测数据是否已排序**

---

## 2. 选择排序（Selection Sort）

- **特点**：每次在剩余元素中选择最小的元素，与当前位置交换。
- **优点**：交换次数少（最多 n-1 次交换），不占用额外空间。
- **缺点**：比较次数依然很多，不稳定（如果交换时跨过了相等元素可能改变顺序）。
- **时间复杂度**：平均、最坏、最好均为 O(n²)
- **空间复杂度**：O(1)
- **适用场景**：
  * **交换成本高**的环境（如Flash存储器）
  * **小规模数据**排序
  * **需要最小化写入次数**的场景

---

## 3. 插入排序（Insertion Sort）

- **特点**：将每个元素插入到前面已排序序列的适当位置。
- **优点**：
  - 对小数据量或基本有序的数据效率很高。
  - 稳定排序，原地排序。
  - 在数据趋于有序时，效率接近 O(n)。
- **缺点**：数据规模大且无序时比较和移动次数多。
- **时间复杂度**：
  - 平均：O(n²)
  - 最坏：O(n²)
  - 最好：O(n)（已有序时）
- **空间复杂度**：O(1)
- **适用场景**：
  * **小数据量**（n < 50）排序
  * **基本有序数据**的排序
  * **作为其他算法的优化子过程**（如快速排序的小数组处理）
  * **在线算法**（数据逐个到达时排序）

---

## 4. 希尔排序（Shell Sort）

- **特点**：是插入排序的改进，通过分组进行间隔排序，逐渐缩小组的间隔，最终变成插入排序。
- **优点**：比 O(n²) 的简单排序快很多，中等规模数据表现不错。
- **缺点**：时间复杂度依赖于间隔序列，不稳定。
- **时间复杂度**：根据间隔序列不同，大约在 O(n log n) 到 O(n^(3/2)) 之间。
- **空间复杂度**：O(1)
- **适用场景**：
  * **中等规模数据**（50 < n < 5000）
  * **需要原地排序**且比插入排序更快的场景
  * **对缓存性能要求不高**的环境

---

## 5. 快速排序（Quick Sort）

* **适用场景**：
  1. 内存连续，缓存友好
  2. 大数据量，数据乱序
  3. 通用内存排序
  4. 对性能要求高的场景

- **特点**：分治法，选取一个基准，将小于基准的放左边，大于基准的放右边，递归排序左右。
- **优点**：平均情况下非常快，缓存友好，原地排序（可做到）。
- **缺点**：最坏情况 O(n²)（如已有序且选基准不好），不稳定。
- **时间复杂度**：
  - 平均：O(n log n)
  - 最坏：O(n²)
  - 最好：O(n log n)
- **空间复杂度**：平均 O(log n)（递归调用栈），最坏 O(n)
- **算法优化**：
  1. 随着快排的进行，数据越来越趋于有序，因此可以在数据量较小时使用插入排序
  2. 采用"三数取中"法（比较数据第一个、最后一个、中间的数这三个数，取数值在中间的数和第一个数交换，然后再开始快排，这样可以杜绝最坏的情况），找合适的基准数

---

## 6. 归并排序（Merge Sort）

- **特点**：分治法，将数组分成两半分别排序，然后合并。
- **优点**：稳定，时间复杂度稳定为 O(n log n)，适合外部排序。
- **缺点**：需要 O(n) 额外空间（非原地）。
- **时间复杂度**：平均、最坏、最好均为 O(n log n)
- **空间复杂度**：O(n) (要用新数组存储排序后的数据，数组最大为数据总量)
- **适用场景**：
  * **需要稳定排序**的场景
  * **外部排序**（数据太大无法全部装入内存）
  * **链表排序**
  * **并行计算**环境

---

## 7. 堆排序（Heap Sort）

- **特点**：利用堆这种数据结构，先建堆，然后不断取出堆顶元素(因为堆顶元素总是最大/最小)。
- **优点**：时间复杂度稳定 O(n log n)，原地排序。
- **缺点**：不稳定，常数因子较大，缓存不友好，sift_down过程中有大量冗余比较
- **时间复杂度**：平均、最坏、最好均为 O(n log n)
- **空间复杂度**：O(1)
- **适用场景**：
  * **内存受限**环境
  * **需要保证最坏情况性能**的实时系统
  * **需要部分排序**（如TopK问题）
  * **优先级队列**实现

---

## 8. 计数排序（Counting Sort）

- **特点**：非比较排序，适用于整数且范围不大的情况。
- **优点**：速度快 O(n+k)，k 为数据范围。
- **缺点**：需要额外空间，只适用于整数且范围小的情况。
- **时间复杂度**：O(n+k)
- **空间复杂度**：O(k)
- **适用场景**：
  * **小范围整数**排序
  * **需要稳定排序**的整数
  * **作为基数排序的子过程**
  * **统计频率**的场景

---

## 9. 桶排序（Bucket Sort）

- **特点**：将数据分到有限数量的桶里，每个桶单独排序（可用其他排序方法），排序后根据每个桶数据的最值进行综合排序
- **优点**：在数据分布均匀时，平均时间复杂度 O(n)。
- **缺点**：需要额外空间，受数据分布影响大。
- **时间复杂度**：平均 O(n+k)，最坏 O(n²)
- **空间复杂度**：O(n+k)
- **适用场景**：
  * **均匀分布数据**排序
  * **外部排序**
  * **非比较排序**适用的场景
  * **浮点数**排序

---

## 10. 基数排序（Radix Sort）

- **特点**：按位排序，从低位到高位（LSD）或高位到低位（MSD），通常使用稳定排序作为子排序。
- **优点**：适用于整数或字符串排序，稳定（如果子排序稳定）。
- **缺点**：需要额外空间，位数多时可能不如快速排序。
- **时间复杂度**：O(d×(n+k))（d 为最大位数，k 为基数大小）
- **空间复杂度**：O(n+k)
- **适用场景**：
  * **整数或字符串**排序
  * **数据位数相对较少**的情况
  * **需要稳定排序**的大整数
  * **多关键字排序**

---

## 排序算法总结表

| 排序算法     | 平均时间复杂度      | 最好情况    | 最坏情况   | 空间复杂度 | 稳定性   | 适用场景               |
| :----------- | :------------------ | :---------- | :--------- | :--------- | :------- | :--------------------- |
| **冒泡排序** | O(n²)               | O(n)        | O(n²)      | O(1)       | ✅ 稳定   | 教学、小规模数据       |
| **选择排序** | O(n²)               | O(n²)       | O(n²)      | O(1)       | ❌ 不稳定 | 交换成本高的场景       |
| **插入排序** | O(n²)               | O(n)        | O(n²)      | O(1)       | ✅ 稳定   | 小规模、基本有序数据   |
| **希尔排序** | O(n log n) O(n^1.3) | O(n log² n) | O(n²)      | O(1)       | ❌ 不稳定 | 中等规模数据           |
| **归并排序** | O(n log n)          | O(n log n)  | O(n log n) | O(n)       | ✅ 稳定   | 大规模、稳定排序需求   |
| **快速排序** | O(n log n)          | O(n log n)  | O(n²)      | O(log n)   | ❌ 不稳定 | 通用、大规模数据       |
| **堆排序**   | O(n log n)          | O(n log n)  | O(n log n) | O(1)       | ❌ 不稳定 | 内存受限、最坏情况保证 |
| **计数排序** | O(n + k)            | O(n + k)    | O(n + k)   | O(k)       | ✅ 稳定   | 整数、小范围数据       |
| **桶排序**   | O(n + k)            | O(n + k)    | O(n²)      | O(n + k)   | ✅ 稳定   | 均匀分布数据           |
| **基数排序** | O(n × k)            | O(n × k)    | O(n × k)   | O(n + k)   | ✅ 稳定   | 整数、字符串排序       |

## 排序算法常见问题

1. STL中使用的sort算法使用的是什么算法？

   * 快速排序算法，数据量<= 32时使用插入排序，递归层数太深时为了防止撑破栈使用堆排序（不使用归并排序是引起其需要占用额外的空间，希尔排序则有最坏的时间复杂度）

2. 如何解决快排时间复杂度恶化问题？

   * 元素较少时使用插入排序
   * 使用"三数取中"法选择基准元素

3. 快速排序递归实现时，怎么解决递归层次过深问题？

   ```c++
   //1.使用ideal - 基于问题规模衰减的方法
   ideal = n;
   while(ideal > 1)
   {
       ideal = (ideal >> 1) + (ideal >> 2);  
       // ideal *= 3/4;
   }
   
   //2.使用递归深度限制 - 固定深度方法
   for(int i =  2 * log₂(n); i > 0; i--)
   {}
   ```

   这两者的区别是，前者的递归深度限制允许比后者稍大

4. 递归过深会导致什么问题？

   * 函数开销变大；导致栈内存溢出，程序挂掉

5. 怎么控制递归深度？如果达到了递归深度还没排完序怎么办？

   * 转成非递归排序算法（比如堆排序）

6. 实际应用中选择排序算法的建议：

   * **n < 50**：插入排序
   * **50 < n < 1000**：希尔排序或快速排序
   * **n > 1000**：快速排序或归并排序
   * **需要稳定性**：归并排序
   * **内存紧张**：堆排序
   * **数据基本有序**：插入排序
   * **数据均匀分布**：桶排序
   * **小范围整数**：计数排序

# 哈希表

## 一、定义
哈希表，又称散列表，是一种通过一个**散列函数 (Hash Function)** 将**键 (Key)** 映射到表中一个位置来访问记录的数据结构。这种映射过程称为**散列 (Hashing)**，映射到的位置称为**哈希地址**或**散列地址**。

**核心思想**：通过键值直接访问，使得在理想情况下，**查找**、插入和删除操作的时间复杂度都可以达到 **O(1)**。

1. **特点**：
   * **键值对存储**：存储的是键 (Key) 和值 (Value) 的配对。
   * **快速访问**：基于键的散列值进行快速查找。
   * **无序性**：元素在表中的存储位置由散列函数决定，与键的原始顺序无关（某些语言的实现，如 `Python 3.7+` 的 `dict`，保持了插入顺序，但这并非哈希表的核心定义特性）。
   * **键唯一性**：通常要求键是唯一的，相同的键经过散列后会指向同一个位置。

2. **优点**：

   - **访问速度快**：在无冲突或冲突较少时，查找、插入、删除的平均时间复杂度为 O(1)。（**应用于查找多的场景**）

   - **实现简单**：核心逻辑清晰，易于编码实现。

   - **灵活性高**：键的类型可以多样（整数、字符串、对象等），只要其可被散列。


3. **缺点**：

   - **空间效率可能低**：为减少冲突，哈希表通常需要预留较大的空闲空间（负载因子控制）。

   - **无序存储**：无法像数组或链表那样保持元素的自然顺序（除非使用额外数据结构）。

   - **哈希冲突不可避免**：只要数据量大于地址空间，根据鸽巢原理，冲突必然发生。

   - **性能不稳定**：最坏情况下，所有键都冲突，导致性能退化为 O(n)。

   - **依赖好的散列函数**：散列函数的质量直接决定了哈希表的性能。


## **二、核心组成部分**

### **1. 常用散列函数 (Hash Function)**
目标：将任意长度的输入（键）映射为固定长度的散列值，并尽可能均匀地分布在地址空间中。

| 方法名                  | 描述                                                         | 公式/示例                                   | 优点                                       | 缺点                                            |
| :---------------------- | :----------------------------------------------------------- | :------------------------------------------ | :----------------------------------------- | :---------------------------------------------- |
| **直接定址法**          | 直接取键的某个线性函数值为散列地址。                         | `hash(key) = a * key + b`                   | 简单，**无冲突**                           | 要求键的分布连续，否则会造成大量空间浪费。      |
| **除留余数法 (最常用)** | 用键除以表长 m 取余数作为散列地址。                          | `hash(key) = key % m`                       | 简单，计算快                               | 表长 m 的选择很关键，通常选**质数**以减少冲突。 |
| **数字分析法**          | 分析键的构成，抽取分布均匀的几位作为散列地址。               | 手机号后四位作为散列值。                    | 适合已知键的分布情况                       | 需要预先知道所有键的分布，通用性差。            |
| **平方取中法**          | 将键平方后，取中间几位作为散列地址。                         | `key=123`，`123^2=15129`，取中间 `512`      | 分布较均匀，隐藏了键的分布                 | 计算成本稍高。                                  |
| **折叠法**              | 将键分割成位数相同的几部分，然后相加作为散列地址。           | `key=123456`，分成 `12|34|56`，相加得 `102` | 适合键位数很多的情况                       | 不一定能保证均匀分布。                          |
| **乘法散列法**          | 1. 用键 k 乘一个常数 A (0<A<1)，取小数部分。<br>2. 再乘以 m 并取整。 | `hash(k) = floor(m * (k * A mod 1))`        | 对 m 的选择不敏感，通常选 2 的幂次         | 计算比除留余数法慢。                            |
| **全域散列法**          | 从一组精心设计的散列函数中随机选择一个来使用。               |                                             | **理论上**可以避免最坏情况，适用于任何键集 | 实现复杂，计算成本高。                          |

### **2. 冲突解决 (Collision Resolution)**
当两个不同的键被映射到同一个哈希地址时，称为**哈希冲突**。解决方法主要分为两类：

#### **A. 开放定址法 (Open Addressing)**
核心思想：当发生冲突时，通过某种**探测序列**在哈希表中寻找下一个空闲位置。

| 方法名                           | 探测序列                                  | 描述                               | 优点                               | 缺点                                                       |
| :------------------------------- | :---------------------------------------- | :--------------------------------- | :--------------------------------- | :--------------------------------------------------------- |
| **线性探测 (Linear Probing)**    | `h(k, i) = (hash(k) + i) % m`             | 顺序检查下一个位置，直到找到空位。 | 实现简单，缓存友好（局部性好）     | **一次聚集**：容易形成连续的被占用块，导致性能下降。       |
| **平方探测 (Quadratic Probing)** | `h(k, i) = (hash(k) + c₁*i + c₂*i²) % m`  | 以平方的步长进行探测。             | 缓解了一次聚集                     | **二次聚集**：可能发生，且不一定能找到空位（即使表未满）。 |
| **双重散列 (Double Hashing)**    | `h(k, i) = (hash₁(k) + i * hash₂(k)) % m` | 使用第二个散列函数来计算探测步长。 | 最好的开放定址方法，消除了聚集现象 | 计算两次散列，成本稍高。                                   |

#### **B. 链地址法 (Separate Chaining)**
核心思想：将映射到同一地址的所有元素存储在一个**链表**中。哈希表的每个位置是一个链表头。

- **操作**：
    - **插入**：计算 `hash(key)`，将键值对插入到对应链表中（头插或尾插）。
    - **查找**：计算 `hash(key)`，在对应链表中顺序查找。
    - **删除**：计算 `hash(key)`，在对应链表中找到并删除节点。
- **优点**：
    - 实现简单。
    - 无聚集现象。
    - 负载因子可以大于 1（链表可以无限延长）。
- **缺点**：
    - 需要额外的指针存储空间。
    - 缓存不友好（节点在内存中不连续）。
    - 小链表情况下性能优异，但链表过长时性能会退化为 O(n)。（在 Java 8 的 `HashMap` 中，当链表长度超过阈值时会转换为红黑树以优化性能）。

## **三、重要概念：负载因子 (Load Factor)**
- **定义**：`α = (表中已存元素个数 n) / (哈希表总大小 m)`。
- **意义**：衡量哈希表的装满程度。
- **作用**：
    - **性能指示器**：负载因子越高，发生冲突的概率越大，哈希表的性能越低。
    - **扩容触发器**：当负载因子超过某个阈值（如 0.75）时，通常需要执行 **Rehash** 操作：创建一个更大的新表，重新计算所有键的哈希值并插入到新表中，以维持 O(1) 的时间复杂度。

# 大数据查重与topk问题

## 哈希表

**原理**

* 基于哈希函数将键(key)映射到数组的特定位置
* 通过解决哈希冲突（开放地址法、链地址法等）来存储多个元素

**优点**

* 查询、插入、删除操作的时间复杂度接近O(1)
* 操作速度快，实现相对简单
* 各种编程语言都有内置实现

**缺点**
* 需要占用较多内存空间，存储效率不高
* 哈希冲突会影响性能
* 无法支持范围查询，只能精确查找

**适用场景**
* 数据量不是特别巨大，需要快速精确查找、去重的场景
* 内存充足时的数据索引和字典类应用

## 位图

**原理**
* 使用比特位来标记元素是否存在
* 每个元素用一个或多个比特位表示
* 通过位运算实现快速的查询和设置

**优点**
* 空间效率极高，特别适合整数型数据
* 查询和设置操作都是O(1)时间复杂度
* 支持快速的位运算操作（与、或、非）

**缺点**
* 只能处理整数类型数据
* 数据范围较大时仍会占用较多内存
* 无法存储额外信息，只能记录存在性

**适用场景**
* 整数数据的大规模存在性判断
* 数据范围相对集中的去重场景
* 需要高性能位运算的应用

## 布隆过滤器

**原理**
* 使用一个大型位数组和多个哈希函数
* 添加元素时，通过多个哈希函数计算多个位置并置为1
* 查询元素时，检查所有哈希位置是否都为1

**优点**
* 空间效率极高，远超过其他数据结构
* 查询时间与数据量大小无关
* 添加和查询操作都是常数时间复杂度

**缺点**
* 存在误判率（可能将不存在的元素判为存在）
* 不能删除已添加的元素（计数布隆过滤器除外）
* 无法实际存储数据本身

**适用场景**
* 大数据量下的快速存在性判断
* 能够接受一定误判率的去重场景
* 缓存穿透防护、爬虫URL去重等
